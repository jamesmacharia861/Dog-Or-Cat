{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4aYvAeP3FaGD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n"
      ],
      "metadata": {
        "id": "MHpay30VFt_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mmSEoXnaIDZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialising the CNN"
      ],
      "metadata": {
        "id": "Bhmu7BByInXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "classifier = Sequential()\n",
        "\n",
        "# Adding a Convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(64, 64, 3), activation='relu'))\n",
        "\n",
        "# Adding another Convolutional layer\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "\n",
        "# Adding Max Pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))"
      ],
      "metadata": {
        "id": "dvGGHlndIsKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening the array\n"
      ],
      "metadata": {
        "id": "ZYBvCuCYP5OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.add(Flatten())\n",
        "classifier.add(Dense(units=128,activation='relu'))\n",
        "classifier.add(Dense(units=1,activation='sigmoid'))"
      ],
      "metadata": {
        "id": "eg1EdXPhQBgG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling"
      ],
      "metadata": {
        "id": "oDzzZLz8QvzB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.compile(optimizer='adam',metrics=['accuracy'],loss='binary_crossentropy')"
      ],
      "metadata": {
        "id": "_xV_5CxgQuJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fiting CNN to images"
      ],
      "metadata": {
        "id": "w7-zp6VlRtMA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")"
      ],
      "metadata": {
        "id": "fBCqb34mRqNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4HG5qwIRYBYN",
        "outputId": "a89e5b6c-4de9-49a4-e25f-64b42844a55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = train_datagen.flow_from_directory(\n",
        "     '/content/drive/My Drive/Colab Notebooks/Train/train_set',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1E_unORU_UK",
        "outputId": "97d2513f-fc56-45a2-bb1a-7a4e7b8d6db5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1065 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_datagen=ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        ")\n",
        "test_set = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/Colab Notebooks/Train/test1',\n",
        "    target_size=(64, 64),\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j0d8fF4FwozA",
        "outputId": "8934f8a7-4f58-4299-af3b-488a668e702f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12502 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have train_set and test_set as your existing TensorFlow Dataset objects\n",
        "\n",
        "# Define the number of epochs for training and validation\n",
        "num_epochs_train = 3  # Number of epochs for training\n",
        "num_epochs_val = 1    # Number of epochs for validation (assuming 1 epoch for validation)\n",
        "\n",
        "# Create repeated datasets for training and validation\n",
        "repeated_train_set = train_set.repeat(num_epochs_train)\n",
        "repeated_val_set = test_set.repeat(num_epochs_val)  # Assuming test_set is used for validation\n",
        "\n",
        "# Define the steps per epoch and validation steps\n",
        "steps_per_epoch = 1200  # Replace with the appropriate number of steps for training\n",
        "validation_steps = 30   # Replace with the appropriate number of steps for validation\n",
        "\n",
        "# Train the classifier using the repeated datasets\n",
        "classifier.fit(\n",
        "    repeated_train_set,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=num_epochs_train,\n",
        "    validation_data=repeated_val_set,\n",
        "    validation_steps=validation_steps\n",
        ")\n"
      ],
      "metadata": {
        "id": "aoW-UvwtdIce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(\n",
        "    train_set,\n",
        "    steps_per_epoch=20,\n",
        "    epochs=5,\n",
        "    validation_data=test_set,\n",
        "    validation_steps=50)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg_u2lD5xzi9",
        "outputId": "0e26c945-045c-46a9-c054-60000f5f7e55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "20/20 [==============================] - 91s 5s/step - loss: 0.6371 - accuracy: 1.0000 - val_loss: 0.6191 - val_accuracy: 1.0000\n",
            "Epoch 2/5\n",
            "20/20 [==============================] - 49s 3s/step - loss: 0.6048 - accuracy: 1.0000 - val_loss: 0.5896 - val_accuracy: 1.0000\n",
            "Epoch 3/5\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.5770 - accuracy: 1.0000 - val_loss: 0.5642 - val_accuracy: 1.0000\n",
            "Epoch 4/5\n",
            "20/20 [==============================] - 35s 2s/step - loss: 0.5534 - accuracy: 1.0000 - val_loss: 0.5419 - val_accuracy: 1.0000\n",
            "Epoch 5/5\n",
            "20/20 [==============================] - 52s 3s/step - loss: 0.5322 - accuracy: 1.0000 - val_loss: 0.5219 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x791a428803a0>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "test_image=image.load_img('/content/drive/My Drive/Colab Notebooks/Train/test1/12499.jpg',target_size=(64,64))\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "result=classifier.predict(test_image)\n",
        "train_set.class_indices\n",
        "if result [0][0]==1:\n",
        "  prediction='dog'\n",
        "else:\n",
        "  prediction='cat'\n",
        "prediction"
      ],
      "metadata": {
        "id": "zTtxVsNH1aZT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "outputId": "2f09d461-2fa2-4b16-a2b7-fa3cce5ff4ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-c69f5ad2af88>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks/Train/test1/12499.jpg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_image\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    420\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Colab Notebooks/Train/test1/12499.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "# Define the directory containing the images\n",
        "directory = '/content/drive/My Drive/Colab Notebooks/Train/validation/'\n",
        "\n",
        "# Load the pre-trained model\n",
        "# Replace 'classifier' with your pre-trained model\n",
        "# classifier = load_model('path_to_your_model')\n",
        "\n",
        "# Mapping of class indices (you might need to adjust this based on your training)\n",
        "class_indices = {0: 'cat', 1: 'dog'}\n",
        "\n",
        "# Iterate through each file in the directory\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith('.jpg') or filename.endswith('.jpeg'):  # Check if the file is an image\n",
        "        image_path = os.path.join(directory, filename)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        test_image = image.load_img(image_path, target_size=(64, 64))\n",
        "        test_image = image.img_to_array(test_image)\n",
        "        test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "        # Make predictions\n",
        "        result = classifier.predict(test_image)\n",
        "        prediction = class_indices[np.argmax(result)]\n",
        "\n",
        "        # Display the filename and predicted class\n",
        "        print(f\"File: {filename} - Predicted: {prediction}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkEcX4t4EiU9",
        "outputId": "fd1e83ac-8fab-43d5-90b0-265ec6aa74ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n",
            "File: cat.14.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: cat.11.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "File: cat.13.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "File: cat.15.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "File: cat.12.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: cat.1.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: cat.10.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: cat.2.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "File: cat.3.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "File: cat.4.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: cat.5.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "File: cat.9.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "File: cat.8.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: cat.7.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "File: cat.6.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "File: dog.15.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: dog.10.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: dog.14.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "File: dog.13.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "File: dog.11.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: dog.1.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: dog.12.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "File: dog.2.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "File: dog.3.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "File: dog.9.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: dog.6.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "File: dog.8.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "File: dog.5.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "File: dog.4.jpg - Predicted: cat\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "File: dog.7.jpg - Predicted: cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = '/content/test1/your_uploaded_image.jpg'  # Replace 'your_uploaded_image.jpg' with the actual image name\n",
        "test_image = image.load_img(image_path, target_size=(64, 64))\n"
      ],
      "metadata": {
        "id": "-acCiPz8LV6T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}